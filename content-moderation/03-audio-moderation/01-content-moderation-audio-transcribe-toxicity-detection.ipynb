{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba3fbe7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Amazon Transcribe Audio Toxicity Detection\n",
    "\n",
    "Amazon Transcribe now provides a simple, ML based solution for toxic content detection in audio chats. The capability available for social media, gaming, and general needs, eliminating the requirement for customers to bring their own data for training the ML model. The toxicity detection feature leverages the context of the conversation and also audio cues(e.g., pitch, tone, emotion) to detect toxic content.\n",
    "\n",
    "In this tutorial we will learn how to detect toxicity in audio files. \n",
    "You can learn more [here](https://aws.amazon.com/transcribe/toxicity-detection/).\n",
    "\n",
    "![audio-moderation-arch](../images/audio-moderation-transcribe-toxicity-detection.png)\n",
    "\n",
    "- [Step 1: Setup Notebook](#step1)\n",
    "- [Step 2: Setup Variables and Import Packages](#step2)\n",
    "- [Step 3: Setup Input Audio File & Run Amazon Transcribe Toxicity Detection Job](#step3)\n",
    "- [Step 4: Check Toxicity Detection Results](#step4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce4449",
   "metadata": {},
   "source": [
    "# Step 1: Setup Notebook <a id=\"step1\"></a>\n",
    "Run the below cell to install/update Python dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a19470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install the below packages\n",
    "%pip install -qU pip\n",
    "%pip install -qU boto3\n",
    "%pip install -qU json2html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b7d0f",
   "metadata": {},
   "source": [
    "# Step 2: Setup Variables and Import Packages <a id=\"step2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b19773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker as sm\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "# variables\n",
    "data_bucket = sm.Session().default_bucket()\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "os.environ[\"BUCKET\"] = data_bucket\n",
    "os.environ[\"REGION\"] = region\n",
    "role = sm.get_execution_role()\n",
    "#The role should have SagemakerFullAccess and TranscribeFullAccess\n",
    "print(f\"SageMaker role is: {role}\\nDefault SageMaker Bucket: s3://{data_bucket}\")\n",
    "\n",
    "s3=boto3.client('s3')\n",
    "transcribe_client=boto3.client('transcribe', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ed969",
   "metadata": {},
   "source": [
    "# Step 3: Setup input audio file & Run Amzon Transcribe Toxicity Detection Job  <a id=\"step3\"></a>\n",
    "Run the below cell to upload a sample audio file (mp3) to the default S3 bucket for Transcribe to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db12285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Here we use a file from the datasets directory and upload it to S3. You can modify the name/path for s3_key, location of audio file to upload. \n",
    "#Also change the name of job_name if you are rerunning the job.\n",
    "s3_key = 'content-moderation-im/audio-moderation/moderation-audio-speech.mp3'\n",
    "s3.upload_file('../datasets/moderation-audio-speech.mp3', data_bucket, s3_key)\n",
    "file_uri = 's3://'+data_bucket+'/'+s3_key\n",
    "print(file_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b261b784",
   "metadata": {},
   "source": [
    "Call Transcribe **StartTranscriptionJob** API and set ToxicityDetection parameter to transcribe the audio to text and detect toxic content.You should also set language to \"en-US\". Currently only English language is supported for this feature. Amazon Transcribe StartTranscriptionJob is an asynchronous API that will start a job managed by Transcribe. We will then call the **GetTranscriptionJob** API to check the job status until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19376545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "job_name = f'toxicity_detection_{str(uuid.uuid1())[0:4]}'\n",
    "\n",
    "transcribe_client.start_transcription_job(\n",
    "        TranscriptionJobName = job_name,\n",
    "        Media = {\n",
    "            'MediaFileUri': file_uri\n",
    "        },\n",
    "        OutputBucketName = data_bucket,\n",
    "        OutputKey = 'content-moderation-im/audio-moderation/my-output-files/',\n",
    "        MediaFormat = 'mp3',\n",
    "        LanguageCode = 'en-US',\n",
    "        ToxicityDetection = [{'ToxicityCategories': ['ALL']}]\n",
    "    )\n",
    "max_tries = 60\n",
    "while max_tries > 0:\n",
    "    max_tries -= 1\n",
    "    job = transcribe_client.get_transcription_job(TranscriptionJobName = job_name)\n",
    "    job_status = job['TranscriptionJob']['TranscriptionJobStatus']\n",
    "    if job_status in ['COMPLETED', 'FAILED']:\n",
    "        print(f\"Job {job_name} is {job_status}.\")\n",
    "        if job_status == 'COMPLETED':\n",
    "            print(\n",
    "                f\"transcription output file copied to\\n\"\n",
    "                f\"\\t{job['TranscriptionJob']['Transcript']['TranscriptFileUri']}.\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Waiting for {job_name}. Current status is {job_status}.\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66ad69",
   "metadata": {},
   "source": [
    "The job is completed. Transcribe stored the toxicity detection output data to a JSON file in the S3 path specified in the `OutputKey` parameter. We now open the transcribed output JSON file from S3 and check the transcription accuracy. Notice that some of the words may be inappropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74061208",
   "metadata": {},
   "source": [
    "# Step 4: Check Toxicity Detection Results <a id=\"step4\"></a>\n",
    "Amazon Transcribe allows you to detect different types of toxic content and also provides a confidence score between 0 and 1 for each category. The supported cateories for toxicity deection includes:\n",
    "\n",
    "* Profanity: Speech that contains words, phrases, or acronyms that are impolite, vulgar, or oﬀensive.\n",
    "* Hate speech: Speech that criticizes, insults, denounces, or dehumanizes a person or group on the basis of an identity (such as race, ethnicity, gender, religion, sexual orientation, ability, and national origin).\n",
    "* Sexual: Speech that indicates sexual interest, activity, or arousal using direct or indirect references to body parts, physical traits, or sex.\n",
    "* Insults: Speech that includes demeaning, humiliating, mocking, insulting, or belittling language. This type of language is also labeled as bullying.\n",
    "* Violence or threat: Speech that includes threats seeking to inﬂict pain, injury, or hostility toward a person or group.\n",
    "* Graphic: Speech that uses visually descriptive and unpleasantly vivid imagery. This type of language is often intentionally verbose to amplify a recipient's discomfort.\n",
    "* Harassment or abusive: Speech intended to aﬀect the psychological well-being of the recipient, including demeaning and objectifying terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20770d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now, let's show reasults in a more readable format.\n",
    "from json2html import *\n",
    "from IPython.display import HTML\n",
    "\n",
    "filename = 'content-moderation-im/audio-moderation/my-output-files/'+job_name+'.json'\n",
    "s3_clientobj = s3.get_object(Bucket=data_bucket, Key=filename)\n",
    "s3_clientdata = s3_clientobj[\"Body\"].read().decode(\"utf-8\")\n",
    "original = json.loads(s3_clientdata)\n",
    "output_transcript = original[\"results\"].get(\"toxicity_detection\")\n",
    "HTML(json2html.convert(json = output_transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a837c",
   "metadata": {},
   "source": [
    "# Cleanup: <a id=\"cleanup\"></a>\n",
    "We will delete the audio file in the S3 bucket and the Audio Filter in Transcribe to clean up resources and prevent unnecessary costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5656824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3.delete_object(Bucket=data_bucket, Key=s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9576b4e9",
   "metadata": {},
   "source": [
    "# Conclusion: <a id=\"conclusion\"></a>\n",
    "In this lab, we learned how to use Toxocity Detection feature with Amazon transcribe for audio moderation."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
