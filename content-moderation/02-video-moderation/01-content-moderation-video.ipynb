{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Moderation - detecting inappropriate stored videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use Amazon Rekognition to detect content that is inappropriate, unwanted, or offensive. You can use Rekognition moderation APIs in social media, broadcast media, advertising, and e-commerce situations to create a safer user experience, provide brand safety assurances to advertisers, and comply with local and global regulations.\n",
    "\n",
    "Amazon Rekognition Video inappropriate or offensive content detection in stored videos is an asynchronous operation. To start detecting inappropriate or offensive content, call [StartContentModeration](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_StartContentModeration.html). Amazon Rekognition Video publishes the completion status of the video analysis to an Amazon Simple Notification Service topic. If the video analysis is successful, call [GetContentModeration](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_GetContentModeration.html) to get the analysis results. For more information about starting video analysis and getting the results, see [Calling Amazon Rekognition Video operations](https://docs.aws.amazon.com/rekognition/latest/dg/api-video.html). \n",
    "\n",
    "In this tutorial, we will show you how to use Amazon Rekognition Moderation API to moderate stored videos. And how to moderate text in a video using Amazon Rekognition and Amazon Comprehend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-moderation-with-text-arc](../images/video-moderation-with-text.png)\n",
    "\n",
    "- [Step 1: Setup Notebook](#step1)\n",
    "- [Step 2: Moderate video using Rekognition video moderation API](#step2)\n",
    "- [Step 3: Moderate text in video](#step3)\n",
    "- [Step 4: Clean up](#step4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Setup Notebook <a id=\"step1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's get the latest installations of our dependencies\n",
    "%pip install --upgrade pip\n",
    "%pip install botocore --upgrade\n",
    "%pip install boto3 --upgrade\n",
    "%pip install -U botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install IPython --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker as sm\n",
    "import os\n",
    "import io\n",
    "import datetime\n",
    "from IPython.display import Video\n",
    "from IPython.display import HTML, display\n",
    "import uuid\n",
    "import json\n",
    "import time\n",
    "\n",
    "# variables\n",
    "data_bucket = sm.Session().default_bucket()\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "os.environ[\"BUCKET\"] = data_bucket\n",
    "os.environ[\"REGION\"] = region\n",
    "role = sm.get_execution_role()\n",
    "\n",
    "print(f\"SageMaker role is: {role}\\nDefault SageMaker Bucket: s3://{data_bucket}\")\n",
    "\n",
    "s3=boto3.client('s3', region_name=region)\n",
    "rekognition=boto3.client('rekognition', region_name=region)\n",
    "sagemaker = boto3.client('sagemaker', region_name=region)\n",
    "comprehend = boto3.client('comprehend', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will moderate a demo video containing a few typical inappropriate scenes, such as alcohol, tobacco, gambling, and suggestive. The video locates at `datasets/moderation-video.mp4`.\n",
    "![video-moderation-data](../images/video-moderation-dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's upload the video to the default S3 bucket for Rekognition to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key = 'content-moderation-im/video-moderation/moderation-video.mp4'\n",
    "s3.upload_file('../datasets/moderation-video.mp4', data_bucket, s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Moderate video using Rekognition moderation API  <a id=\"step2\"></a>\n",
    "Call Rekognition **StartContentModeration** API to detect inappropriate information in the video. Rekognition Video moderation API is an asynchronize API that will start a job managed by Rekognition. We will receive a job_id back when we start the job. Then use iteration logic to heart-beat the **GetContentModeration** API to check job status until the job completes.\n",
    "The below process should take ~1 minute to complete.\n",
    "\n",
    "However, it is highly recommended to check out the Notification Channel feature which allows you to receive a SNS notification when the detection job is completed instead of periodically polling the status of the detection. Check [boto3 document](https://docs.aws.amazon.com/cli/latest/reference/rekognition/start-content-moderation.html) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startModerationLabelDetection = rekognition.start_content_moderation(\n",
    "    Video={\n",
    "        'S3Object': {\n",
    "            'Bucket': data_bucket,\n",
    "            'Name': s3_key,\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "moderationJobId = startModerationLabelDetection['JobId']\n",
    "display(\"Job Id: {0}\".format(moderationJobId))\n",
    "\n",
    "getContentModeration = rekognition.get_content_moderation(\n",
    "    JobId=moderationJobId,\n",
    "    SortBy='TIMESTAMP'\n",
    ")\n",
    "\n",
    "while(getContentModeration['JobStatus'] == 'IN_PROGRESS'):\n",
    "    time.sleep(5)\n",
    "    print('.', end='')\n",
    "\n",
    "    getContentModeration = rekognition.get_content_moderation(\n",
    "    JobId=moderationJobId,\n",
    "    SortBy='TIMESTAMP')\n",
    "\n",
    "display(getContentModeration['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the video and labels in HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_video_url = s3.generate_presigned_url('get_object', Params={'Bucket': data_bucket, 'Key': s3_key})\n",
    "video_tag = f\"<video id='cccvid1' controls='controls' width='640' height='360' name='Video' src='{s3_video_url}'></video>\"\n",
    "\n",
    "label_html = ''''''\n",
    "for label in getContentModeration[\"ModerationLabels\"]:\n",
    "    if len(label[\"ModerationLabel\"][\"ParentName\"]) > 0:\n",
    "        label_html += f'''<a onclick=\"document.getElementById('cccvid1').currentTime={round(label['Timestamp']/1000)}\">[{label['Timestamp']} ms]: \n",
    "                {label['ModerationLabel']['Name']}, confidence: {round(label['ModerationLabel']['Confidence'])}</a><br/>\n",
    "                '''\n",
    "display(HTML(video_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below file to print out all the detected labels. Click on the item to navigate to the above video's timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(HTML(label_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Moderate text in video <a id=\"step3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text detection with Amazon Rekognition Video is an asynchronous operation. You start text detection by calling **StartTextDetection** which returns a job identifier (JobId ) When the text detection operation finishes, Amazon Rekognition publishes a completion status to the Amazon Simple Notification Service topic registered in the initial call to **StartTextDetection**. To get the results of the text detection operation, first check that the status value published to the Amazon SNS topic is SUCCEEDED . if so, call **GetTextDetection** and pass the job identifier (JobId ) from the initial call of **StartLabelDetection**.\n",
    "\n",
    "The below process should take ~1 minute to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTextDetection = rekognition.start_text_detection(\n",
    "    Video={\n",
    "        'S3Object': {\n",
    "            'Bucket': data_bucket,\n",
    "            'Name': s3_key,\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "textJobId = getTextDetection['JobId']\n",
    "display(\"Job Id: {0}\".format(moderationJobId))\n",
    "\n",
    "getTextDetection = rekognition.get_text_detection(JobId=textJobId)\n",
    "\n",
    "while(getTextDetection['JobStatus'] == 'IN_PROGRESS'):\n",
    "    time.sleep(5)\n",
    "    print('.', end='')\n",
    "\n",
    "    getTextDetection = rekognition.get_text_detection(JobId=textJobId)\n",
    "\n",
    "display(getTextDetection['JobStatus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's display the video and use the hyperlinks to navigate the timestamps where text was detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_video_url = s3.generate_presigned_url('get_object', Params={'Bucket': data_bucket, 'Key': s3_key})\n",
    "video_tag = f\"<video id='cccvid2' controls='controls' width='640' height='360' name='Video' src='{s3_video_url}'></video>\"\n",
    "\n",
    "text_html = ''''''\n",
    "for txt in getTextDetection[\"TextDetections\"]:\n",
    "    if txt[\"TextDetection\"][\"Type\"] == 'LINE':\n",
    "        text_html += f'''<a onclick=\"document.getElementById('cccvid2').currentTime={round(txt['Timestamp']/1000)}\">[{txt['Timestamp']} ms]: \n",
    "                {txt[\"TextDetection\"][\"DetectedText\"]}, confidence: {round(txt[\"TextDetection\"][\"Confidence\"],2)}</a><br/>\n",
    "                '''\n",
    "display(HTML(video_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below file to print out all the detected texts. Click on the item to navigate to the above video's timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(HTML(text_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting texts from the video, we can then moderate the texts using Amazon Comprehend. \n",
    "\n",
    "### [Amazon Comprehend](https://aws.amazon.com/comprehend/) is a managed AI service for Nature Language Processing and text analysis.\n",
    "You can use the Amazon Comprehend console or APIs to detect personally identifiable information (PII) in English text documents. PII is a textual reference to personal data that could be used to identify an individual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_text_list=[]\n",
    "textDetections=getTextDetection['TextDetections']\n",
    "for text in textDetections:\n",
    "    if text[\"TextDetection\"]['Type'] == 'LINE' and text[\"TextDetection\"]['DetectedText'] not in detected_text_list:\n",
    "        detected_text_list.append(text[\"TextDetection\"]['DetectedText'])\n",
    "    \n",
    "    \n",
    "for text in detected_text_list:\n",
    "    response=comprehend.detect_pii_entities(Text=text, LanguageCode='en')\n",
    "    if len(response['Entities']) > 0: \n",
    "        print ('Detected text:' + text)\n",
    "        print(\"Detected PII entity is: \" + text[response['Entities'][0]['BeginOffset']:response['Entities'][0]['EndOffset']])\n",
    "        print(\"PII type is: \" + response['Entities'][0]['Type'])\n",
    "        print(\"Confidence score is: \" + str(response['Entities'][0]['Score']))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Clean up <a id=\"step4\"></a>\n",
    "\n",
    "Remove the resources that may incur the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the image from s3 bucket\n",
    "response = s3.delete_object(Bucket=data_bucket, Key=s3_key)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this lab, we moderated a video (containing text) using Amazon Rekognition and Amazon Comprehend."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
