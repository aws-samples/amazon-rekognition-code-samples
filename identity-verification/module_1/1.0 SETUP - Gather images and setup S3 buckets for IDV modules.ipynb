{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather images and prepare them for labs\n",
    "----\n",
    "\n",
    "This notebook downloads and prepares \"Labeled Faces in the Wild\" images using sklearn's fetch_lfw_people function. It converts the images from jpg to png, creates an S3 bucket which will be used in the subsequent modules, and uploads a sample of the images to that bucket. \n",
    "\n",
    "1. Create a S3 bucket \n",
    "2. Download and un-tar \"Labeled Faces in the Wild\" images.\n",
    "3. Convert images from jpg to png (or jpeg)(Rekognition only supports png and jpeg images)\n",
    "4. Upload converted images to the S3 bucket.\n",
    "5. Upload contents of media directory to the S3 bucket. \n",
    "\n",
    "\n",
    "###  Information on \"Labeled Faces in the Wild\":\n",
    "-----\n",
    "*Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\n",
    "Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments.\n",
    "University of Massachusetts, Amherst, Technical Report 07-49, October, 2007* [pdf](https://vis-www.cs.umass.edu/lfw/lfw.pdf)\n",
    "\n",
    "\n",
    "### Information on sklearn.datasets.fetch_lfw_people\n",
    "\n",
    "Sklearn provides [fetch_lfw_people](https://scikit-learn.org/stable/datasets/real_world.html#labeled-faces-in-the-wild-dataset) this function will perform a one time download the images and tasks into the data directory of sklearn. Note: this will take several minutes to download the first time it is run. The LFW dataset is a collection of JPEG pictures of famous people collected over the internet, all details are available on the official website:\n",
    "\n",
    "https://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "Each picture is centered on a single face. The typical task is called Face Verification: given a pair of two pictures, a binary classifier must predict whether the two images are from the same person.\n",
    "\n",
    "\n",
    "####Â Install python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3 matplotlib opencv-python openpyxl pandas sklearn scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries & Specify a S3 bucket name\n",
    "\n",
    "Update the name of the bucket you want created on your behalf. This bucket will be used in subsequent modules and will be loaded with a sample of the \"Labeled Faces in the Wild\" images \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import boto3\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "\n",
    "mySession = boto3.session.Session()\n",
    "aws_region = mySession.region_name\n",
    "print(\"AWS Region: {}\".format(aws_region))\n",
    "\n",
    "# --- sklearn libraries for Labeled Faces in the Wild --- \n",
    "from sklearn.datasets import fetch_lfw_people, get_data_home\n",
    "\n",
    "# --- provide a bucket name ---\n",
    "bucket_name = \"\"\n",
    "# -------------------------------------------\n",
    "\n",
    "print(\"AWS Bucket: {}\".format(bucket_name))\n",
    "%store bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Create an S3 Bucket \n",
    "----\n",
    "The following will create a new S3 bucket which will store images and other objects that are used in subsequent modules. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "try:\n",
    "   s3.create_bucket(\n",
    "       Bucket=bucket_name,\n",
    "       CreateBucketConfiguration={'LocationConstraint': aws_region}\n",
    "   )\n",
    "except:\n",
    "    print(\"bucket already exits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Download Labeled Faces in the Wild\n",
    "------\n",
    "\n",
    "The Labeled Faces in the Wild is a database of face photographs designed for studying the problem of unconstrained face recognition. The data set contains more than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people have two or more distinct photos. More details can be found here: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "\n",
    "**NOTE: using the sklearn.datasets.fetch_lfw_people function will take several minutes to download!**  \n",
    "\n",
    "fetch_lfw_people is a one time download, and will write the faces to **jpg** the sklearn data home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -- download image pairs --\n",
    "fetch_lfw_people(min_faces_per_person=2,  download_if_missing = True)\n",
    "# -- get the path to lfw image data --\n",
    "lfw_path = \"{}/lfw_home/lfw_funneled/\".format(get_data_home())\n",
    "print(lfw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Convert images from jpg to png (or jpeg)\n",
    "-----\n",
    "Rekognition supports png and jpeg images, here we are going to read the \"jpg\" images, convert them to png and save them in a directory called idv_media. In this step we are simply extracting images that start with the letter \"A\". \n",
    "\n",
    "\n",
    "**NOTE: this may take a minute or two to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delete existing idv-media directory(if it exists), then create the idv-media directory \n",
    "!rm -R idv-media\n",
    "!mkdir idv-media\n",
    "\n",
    "pattern = \"lfw_funneled/*/*.jpg\" \n",
    "pattern = \"{}/*/*.jpg\".format(lfw_path)\n",
    "for img in glob.glob(pattern):\n",
    "    file_and_path = Path(img)\n",
    "    filename_replace_ext = file_and_path.with_suffix('.png')\n",
    "    file_name = os.path.basename(filename_replace_ext)\n",
    "    if file_name[0] == \"A\":\n",
    "        print(file_name)\n",
    "        im1 = Image.open(img)\n",
    "        full_path = os.path.join(os.getcwd(), \"idv-media\", file_name)\n",
    "        resp = im1.save(full_path)\n",
    "    \n",
    "print(\"-- conversion complete --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Upload Images to S3 bucket\n",
    "----\n",
    "This step reads all of the \"png\" files in the idv_media folder and uploads them to the S3 bucket. \n",
    "\n",
    "**NOTE: this may take a few minutes to upload to S3** (yes we could try and do this in parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# S3 upload converted images\n",
    "destination_path = \"idv-media/*.png\"\n",
    "for img in glob.glob(destination_path):\n",
    "    file_name = os.path.basename(img)\n",
    "    s3.upload_file(img, bucket_name, file_name)\n",
    "print(\"-- upload complete --\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Upload media images and file to S3 bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 upload media folder\n",
    "destination_path = \"media/*\"\n",
    "for img in glob.glob(destination_path):\n",
    "    file_name = os.path.basename(img)\n",
    "    s3.upload_file(img, bucket_name, file_name)\n",
    "print(\"-- upload complete --\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
