{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Verification Getting Started\n",
    "\n",
    "-------\n",
    "\n",
    "This lab simply checks to make sure that your environment is setup to run the identity verification labs. There are no-non standard libraries, however you want to make sure that boto3 is installed and updated. \n",
    "\n",
    "You can read more about boto3 here: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html\n",
    "\n",
    "\n",
    "### Check the Python Environment is Setup\n",
    "-----\n",
    "Make sure that the following blocks of code will run, make any changes to your region, bucket and clients necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "from IPython.display import display, Image as IImage\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "%store -r bucket_name\n",
    "mySession = boto3.session.Session()\n",
    "aws_region = mySession.region_name\n",
    "print(\"AWS Bucket: {}\".format(bucket_name))\n",
    "print(\"AWS Bucket: {}\".format(aws_region))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Clients \n",
    "-----\n",
    "Here we are going to use both S3 and Rekognition clients  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client  = boto3.client('s3')\n",
    "rek_client = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a Face from S3\n",
    "-------\n",
    "Here we are going to display a face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image of a Face\n",
    "face_image = \"face_1_0.jpeg\"\n",
    "print(face_image)\n",
    "display(IImage(url=s3_client.generate_presigned_url('get_object', \n",
    "                                                    Params={'Bucket': bucket_name, \n",
    "                                                            'Key'   : face_image})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  This function will list the files stored in our bucket. \n",
    "-----\n",
    "We'll make use of these files in subsequent labs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_s3_files_using_client(bucket_name):\n",
    "    \"\"\"\n",
    "    This functions list all files in s3 bucket.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    print(f\"Files located in bucket: {bucket_name}\")\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    files = response.get(\"Contents\")\n",
    "    for file in files:\n",
    "        print(f\"file_name: {file['Key']}, size: {file['Size']}\")\n",
    "\n",
    "# -- run our function \n",
    "list_s3_files_using_client(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Rekognition APIs\n",
    "-----\n",
    "Here we'll use the detect_faces API to ensure that our Rekognition client is properly configured and we have the appropriate permissions. The following will produce a FaceDetails object. Take a moment to look at the result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rek_client.detect_faces(Image={'S3Object':{\n",
    "    'Bucket': bucket_name,\n",
    "    'Name'  : face_image}},\n",
    "    Attributes=['ALL'])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw a Bounding Box around the detected Face\n",
    "-----\n",
    "Amazon Rekognition Image operations can return bounding boxes coordinates for items that are detected in images. For example, the DetectFaces operation returns a bounding box (BoundingBox) for each face detected in an image. You can use the bounding box coordinates to display a box around detected items. \n",
    "\n",
    "A BoundingBox has the following properties:\n",
    "\n",
    "- Height – The height of the bounding box as a ratio of the overall image height.\n",
    "- Left – The left coordinate of the bounding box as a ratio of overall image width.\n",
    "- Top – The top coordinate of the bounding box as a ratio of overall image height.\n",
    "- Width – The width of the bounding box as a ratio of the overall image width.\n",
    "\n",
    "Each BoundingBox property has a value between 0 and 1. Each property value is a ratio of the overall image width (Left and Width) or height (Height and Top). For example, if the input image is 700 x 200 pixels, and the top-left coordinate of the bounding box is 350 x 50 pixels, the API returns a Left value of 0.5 (350/700) and a Top value of 0.25 (50/200).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_faces(photo,bucket):\n",
    "     \n",
    "    client=boto3.client('rekognition')\n",
    "\n",
    "    # Load image from S3 bucket\n",
    "    s3_connection = boto3.resource('s3')\n",
    "    s3_object = s3_connection.Object(bucket,photo)\n",
    "    s3_response = s3_object.get()\n",
    "\n",
    "    stream = io.BytesIO(s3_response['Body'].read())\n",
    "    image=Image.open(stream)\n",
    "    \n",
    "    #Call DetectFaces \n",
    "    response = client.detect_faces(Image={'S3Object': {'Bucket': bucket, 'Name': photo}},\n",
    "        Attributes=['ALL'])\n",
    "\n",
    "    imgWidth, imgHeight = image.size  \n",
    "    draw = ImageDraw.Draw(image)  \n",
    "                    \n",
    "    # calculate and display bounding boxes for each detected face       \n",
    "    print('Detected face for ' + photo)    \n",
    "    for faceDetail in response['FaceDetails']:\n",
    "        print('Predicted age between ' + str(faceDetail['AgeRange']['Low']) \n",
    "              + ' and ' + str(faceDetail['AgeRange']['High']) + ' years old')\n",
    "        \n",
    "        box = faceDetail['BoundingBox']\n",
    "        left = imgWidth * box['Left']\n",
    "        top = imgHeight * box['Top']\n",
    "        width = imgWidth * box['Width']\n",
    "        height = imgHeight * box['Height']\n",
    "                \n",
    "\n",
    "        print('Left: ' + '{0:.0f}'.format(left))\n",
    "        print('Top: ' + '{0:.0f}'.format(top))\n",
    "        print('Face Width: ' + \"{0:.0f}\".format(width))\n",
    "        print('Face Height: ' + \"{0:.0f}\".format(height))\n",
    "\n",
    "        points = (\n",
    "            (left,top),\n",
    "            (left + width, top),\n",
    "            (left + width, top + height),\n",
    "            (left , top + height),\n",
    "            (left, top)\n",
    "\n",
    "        )\n",
    "        draw.line(points, fill='#00d400', width=4)\n",
    "        \n",
    "        display(image)\n",
    "\n",
    "\n",
    "    return len(response['FaceDetails'])\n",
    "\n",
    "response = show_faces(face_image,bucket_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
